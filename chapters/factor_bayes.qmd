---
title: "ComparaciÃ³n de modelos mediante Factores de Bayes"
format: html
execute:
  echo: true   # Muestra el cÃ³digo
  warning: false  # Oculta advertencias
  fig-width: 12   # Ancho del grÃ¡fico
  fig-height: 8   # Altura del grÃ¡fico
---

Cuando trabajamos con datos es comÃºn tener **varios modelos posibles** que podrÃ­an explicar esos datos. Algunos modelos son **simples** (con pocos parÃ¡metros) y otros **complejos** (con mÃ¡s parÃ¡metros).

**Problema al elegir modelos:**

| Si usamos un modelo muy simple            | Si usamos un modelo muy complejo                                |
|-----------------------------|-------------------------------------------|
| âŒ No captura toda la informaciÃ³n (sesgo) | âŒ Se ajusta demasiado a los datos (sobreajuste, alta varianza) |

Por eso, necesitamos una manera objetiva de decidir quÃ© modelo es mejor.

## Â¿QuÃ© son los Factores de Bayes (Bayes Factors)?

Los **Factores de Bayes (BF)** son una herramienta para **comparar dos modelos** ($M_0$ y $M_1$) segÃºn **quÃ© tan bien explican los datos**.

ðŸ‘‰ Se basan en la **razÃ³n (cociente)** entre las **verosimilitudes marginales** de cada modelo:

$$
BF(M_0, M_1) = \frac{P(X | M_0)}{P(X | M_1)}
$$

Donde:

-   $P(X | M_0)$ = Verosimilitud marginal del modelo $M_0$ dado los datos X
-   $P(X | M_1)$ = Verosimilitud marginal del modelo $M_1$

**InterpretaciÃ³n intuitiva:**

| Valor del BF | InterpretaciÃ³n                                           |
|--------------|----------------------------------------------------------|
| $BF > 1$     | Los datos favorecen el **modelo** $M_0$ sobre $M_1$ |
| $BF < 1$     | Los datos favorecen el **modelo** $M_1$ sobre $M_0$ |

## Â¿QuÃ© es la verosimilitud marginal?

La **verosimilitud marginal** de un modelo $M_i$ es:

$$P(Xâˆ£M_i)=âˆ«P(Xâˆ£Î¸iâ€‹)P(Î¸iâ€‹)dÎ¸iâ€‹$$

ðŸ”‘ Es decir:

-   **La probabilidad de los datos** bajo el modelo $M_i$, **promediando** sobre **todos los posibles valores** de los parÃ¡metros $\theta_i$, segÃºn las distribuciones a priori.

ðŸ’¡ **InterpretaciÃ³n**: Nos dice **quÃ© tan bien explica el modelo los datos**, considerando **todas las incertidumbres en los parÃ¡metros**.

## Â¿Por quÃ© es difÃ­cil calcular la verosimilitud marginal?

-   En modelos complejos (como los filogenÃ©ticos o de sustituciÃ³n de secuencias), **esa integral es imposible de resolver de forma exacta**.

-   Tiene **muchos parÃ¡metros** y **espacios de probabilidad muy grandes**.

-   Por eso, **necesitamos mÃ©todos numÃ©ricos que nos ayuden a estimarla**.

## SoluciÃ³n: MÃ©todos basados en MCMC

âž¡ï¸ AquÃ­ es donde entran **Stepping-Stone Sampling** y **Path Sampling**, que son **mÃ©todos basados en MCMC** (Markov Chain Monte Carlo).

Ambos mÃ©todos:

-   Nos permiten **estimar la verosimilitud marginal** de manera aproximada pero **con gran precisiÃ³n**.

-   Son **mÃ¡s robustos y confiables** que intentar calcular la integral directamente.

![](/images/u1_PatDiv/ss.png){fig-align="center" width="850"}

**En la figura 6 piedras:**

-   6 stones (piedras) significan 6 powers (Î²):

Î² = 0/6, 1/6, 2/6, 3/6, 4/6, 5/6, 6/6

O sea: 0, 0.166, 0.333, 0.5, 0.666, 0.833, 1.

Cada una te da una mezcla distinta de prior y posterior, y en cada una corres un MCMC.

-   **Î² = 0/6 = 0** â†’ solo prior.

-   **Î² = 6/6 = 1** â†’ solo posterior.

-   **Intermedios (0 \< Î² \< 1)** â†’ mezcla de prior y posterior.

## ðŸŒ‰ Stepping-Stone Sampling

ðŸ”¹ Â¿QuÃ© hace?

-   **Divide el camino** entre la prior y la posterior en **pequeÃ±os pasos (piedras)**.

-   En cada piedra, se hace una **simulaciÃ³n MCMC** para obtener informaciÃ³n de ese punto.

-   Al final, **suma toda la informaciÃ³n** para calcular la verosimilitud marginal.

ðŸ”¹ **AnalogÃ­a**:

> Es como **cruzar un rÃ­o saltando por piedras**, donde cada piedra es una mezcla distinta de prior y posterior.

------------------------------------------------------------------------

## ðŸ›¤ Path Sampling

ðŸ”¹ Â¿QuÃ© hace?

-   En vez de ir por piedras, hace un **camino continuo** desde la prior hasta la posterior.

-   Va **midiendo la log-verosimilitud** a cada paso.

-   Al final, **suma (integra)** toda esa informaciÃ³n.

ðŸ”¹ Â¿CÃ³mo se hace?

-   Calcula **el Ã¡rea bajo la curva** de log-verosimilitud vs Î².

ðŸ”¹ **AnalogÃ­a**:

> Es como **caminar por todo el rÃ­o, sin saltos**, y anotar cÃ³mo cambia la corriente a cada paso.

## **Stepping-Stone Sampling** y **Path Sampling en Revbayes**

Este mÃ©todo calcula un **vector de potencias (powers)** a partir de una **distribuciÃ³n beta**, y luego realiza una **simulaciÃ³n MCMC** para cada valor de esa potencia, **elevando la verosimilitud a esa potencia**.

En esta implementaciÃ³n, el **vector de potencias comienza en 1** (donde la verosimilitud se parece a la posterior), y **va disminuyendo gradualmente hacia 0**, acercÃ¡ndose a la prior.

Este procedimiento para estimar la **verosimilitud marginal** es vÃ¡lido para **cualquier modelo en RevBayes**. Primero, creamos una **variable que contiene el anÃ¡lisis de power-posterior**. Para eso, debemos indicar el modelo, los movimientos (moves), los monitores, y el nombre del archivo de salida. El argumento `cats` define **el nÃºmero de piedras (stepping stones)**.

## Descarga el script para este ejercicio:

ðŸ“¥ [Diversificacion de Eupomphini con tres intervalos](../docs/u1_PatDiv/Eupomphini_EBD_3.Rev)

**Comando para definir el anÃ¡lisis de power-posterior:**

``` r
pow_p = powerPosterior(mymodel, moves, monitors, "output/model1.out", cats=50)
```

-   cats=50: nÃºmero de piedras (50 pasos entre prior y posterior).

**Importante: hacer "burn-in" antes de empezar:**

Antes de empezar el anÃ¡lisis real, hacemos un burn-in para que la simulaciÃ³n no empiece desde un valor raro, sino desde un lugar donde ya la MCMC estÃ¡ estable.

``` r
pow_p.burnin(generations=10000, tuningInterval=1000)
```

-   Corre 10,000 generaciones antes de empezar a recolectar datos.
-   Ajusta los movimientos cada 1000 generaciones.

**Ahora, correr el anÃ¡lisis de power-posterior:**

``` r
pow_p.run(generations=1000)
```

-   Corre 1,000 generaciones por cada piedra (por cada valor de Î²).
-   Con 50 piedras (cats), harÃ¡s 50 simulaciones MCMC distintas (una por cada Î²).

**Cuando termina, hacer el cÃ¡lculo de Stepping-Stone Sampling:** Ya que se guardaron los resultados de cada piedra en el archivo, podemos crear un objeto para calcular la verosimilitud marginal por Stepping-Stone:

``` r
ss = steppingStoneSampler(file="output/model1.out", powerColumnName="power", likelihoodColumnName="likelihood")
```

-   powerColumnName: nombre de la columna con los Î² (normalmente "power").
-   likelihoodColumnName: nombre de la columna con las verosimilitudes (normalmente "likelihood").

**Para obtener la verosimilitud marginal por Stepping-Stone Sampling:**

``` r
write("Stepping stone marginal likelihood:\t", ss.marginal() )
```

**Si quieres tambiÃ©n Path Sampling (opcional y recomendable para comparar):** Usa el mismo archivo para crear un estimador con path sampling:

``` r
ps = pathSampler(file="output/model1.out", powerColumnName="power", likelihoodColumnName="likelihood")
```

**Para calcular la verosimilitud marginal por Path Sampling:**

``` r
write("Path-sampling marginal likelihood:\t", ps.marginal() )
```

## Â¿CÃ³mo comparamos los modelos con Factores de Bayes?

ðŸ”‘ **Paso 1. Recordemos quÃ© es el Factor de Bayes (BF):**

El **Factor de Bayes** compara dos modelos, por ejemplo:

-   $M_0$: Modelo simple (ej. DiversificaciÃ³n con 3 intervalos).

-   $M_1$: Modelo complejo (ej. DiversificaciÃ³n con 5 intervalos).

ðŸ”‘ **Paso 2. Â¿CÃ³mo lo calculamos?**

âš ï¸ Importante: Las verosimilitudes marginales se guardan como **log-verosimilitudes** (log-marginal likelihoods), porque son nÃºmeros muy pequeÃ±os [problema de desbordamiento numÃ©rico](https://es.wikipedia.org/wiki/Desbordamiento_aritm%C3%A9tico).

Por eso, usamos la **forma logarÃ­tmica del Factor de Bayes**, que llamamos **K**:

$$
K = ln[BF(M_0, M_1)] = ln[P(X | M_0)] - ln[P(X | M_1)]
$$

âš™ï¸ Donde:

-   $ln[P(X | M_0)]$: log-verosimilitud marginal del modelo simple ($M_0$).

-   $ln[P(X | M_1)]$: log-verosimilitud marginal del modelo complejo ($M_1$).

**Paso 3. Interpretar K:**

| Valor de $K$ | InterpretaciÃ³n                          | Modelo preferido         |
|------------------|---------------------------------|---------------------|
| $K > 1$            | Soporte a favor de M0                   | M0 (modelo simple)       |
| $K < -1$           | Soporte a favor de M1                   | M1 (modelo complejo)     |
| $-1 < K < 1$       | Sin preferencia clara entre los modelos | Ninguno claramente mejor |

> **Nota:** Para convertirlo a Factor de Bayes "real", solo elevas $e^k$, pero normalmente usamos $K$ directamente para comparar.

**Ejemplo (con nÃºmeros inventados para ilustrar):**

**Tabla 1. Probabilidades marginales:**

| Modelo                                   | Path Sampling (lnL)               | Stepping-Stone (lnL)              |
|---------------------------|----------------------|-----------------------|
| $M_0$ - DiversificaciÃ³n con 3 intervalos | -120.5                            | -119.8                            |
| $M_1$ - DiversificaciÃ³n con 5 intervalos | -122.1                            | -122.0                            |
| $K$                                | $(-120.5) - (-122.1) = 1.6$ | $(-119.8) - (-122.0) = 2.2$ |

**InterpretaciÃ³n segÃºn la escala de Jeffreys:**

| Valor de $K$   | InterpretaciÃ³n          |
|------------|-------------------------|
| 0 a 1.16   | MenciÃ³n mÃ­nima (dÃ©bil). |
| 1.16 a 2.3 | Evidencia sustancial.   |
| 2.3 a 4.6  | Evidencia fuerte.       |
| > 4.6     | Evidencia decisiva.     |

ðŸ’¡ En el ejemplo:

-   Con **$K$ = 2.2 (SS)** â†’ Evidencia **sustancial a favor de $M_0$**.

-   Con **$K$ = 1.6 (PS)** â†’ TambiÃ©n evidencia **sustancial a favor de $M_0$**.

