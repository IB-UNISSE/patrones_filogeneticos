---
title: "Apuntes sobre RevBayes"
format: html
---

# Introducci√≥n a la Inferencia Bayesiana

La **inferencia bayesiana** es un enfoque de la estad√≠stica que permite actualizar nuestras creencias sobre un par√°metro desconocido **a medida que obtenemos nueva informaci√≥n**. Se basa en el **Teorema de Bayes**, que nos dice c√≥mo combinar la informaci√≥n previa con la evidencia observada.

El **Teorema de Bayes** se expresa matem√°ticamente como:

$$
P(\theta | D) = \frac{P(D | \theta) P(\theta)}{P(D)}
$$

-   Donde: $P(\theta | D)$ es la **probabilidad posterior** del par√°metro $\theta$ despu√©s de observar los datos $D$

-   $P(D | \theta)$ es la **verosimilitud**, la probabilidad de los datos $D$ dados un valor del par√°metro $\theta$.

-   $P(\theta)$ es la **distribuci√≥n prior**, que refleja nuestra creencia sobre $\theta$ antes de observar los datos

-   $P(D)$ es la **evidencia**, un factor de normalizaci√≥n que garantiza que la probabilidad total sea 1.

El **objetivo de la inferencia bayesiana** es calcular la **distribuci√≥n posterior**, que nos proporciona una estimaci√≥n m√°s precisa del par√°metro $\theta$ al incorporar tanto datos como conocimiento previo.

# Diferencia entre Inferencia Bayesiana y M√°xima Verosimilitud

| **Enfoque**                        | **M√°xima Verosimilitud (MV)**                                            | **Inferencia Bayesiana**                                                    |
|------------------------------------|--------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| **Pregunta clave**                 | ¬øCu√°l es el valor de $\theta$ que maximiza la probabilidad de los datos? | ¬øC√≥mo cambia nuestra creencia sobre $\theta$ despu√©s de observar los datos? |
| **Ecuaci√≥n base**                  | $$ \hat{\theta} = \arg\max_{\theta} P(D | \theta) $$                     | $$ P(\theta | D) \propto P(D | \theta) P(\theta) $$                         |
| **Uso de informaci√≥n previa?**     | ‚ùå No                                                                    | ‚úÖ S√≠ (usa una distribuci√≥n prior)                                          |
| **Resultado**                      | Un solo valor √≥ptimo para $\theta$                                       | Una distribuci√≥n completa sobre $\theta$                                    |
| **Estimaci√≥n de incertidumbre?**   | ‚ùå No la estima                                                          | ‚úÖ S√≠, con la distribuci√≥n posterior                                        |
| **Flexibilidad con nuevos datos?** | ‚ùå No se actualiza f√°cilmente                                            | ‚úÖ Se actualiza din√°micamente con m√°s datos                                 |

# ¬øQu√© es RevBayes?

A diferencia de otros programas, **RevBayes** se basa en un **lenguaje declarativo y probabil√≠stico**, lo que permite definir modelos gr√°ficos y realizar inferencia mediante **Markov Chain Monte Carlo (MCMC)**.

**Principales caracter√≠sticas de RevBayes:**

-   Utiliza **modelos gr√°ficos probabil√≠sticos**.

-   Tiene una sintaxis similar a **R**, pero con mayor enfoque en la inferencia bayesiana.

-   Permite definir relaciones entre variables mediante **nodos**.

-   Utiliza **muestreo MCMC** para estimar distribuciones posteriores.

# ¬øQu√© es el Muestreo MCMC?

El **Muestreo MCMC (Markov Chain Monte Carlo)** es un conjunto de m√©todos computacionales utilizados para **aproximar distribuciones de probabilidad complejas**, especialmente en **inferencia bayesiana** y problemas donde el espacio de par√°metros es muy grande.

## ¬øPor qu√© se necesita MCMC?

En inferencia bayesiana, la distribuci√≥n posterior de un par√°metro $\theta$ se calcula usando:

$$
P(\theta | D) = \frac{P(D | \theta) P(\theta)}{P(D)}
$$

Pero en la pr√°ctica, el denominador $P(D)$ es dif√≠cil de calcular, ya que requiere integrar sobre todos los valores posibles de $\theta$:

$$
P(D) = \int P(D | \theta) P(\theta) d\theta
$$

Cuando el espacio de par√°metros es muy grande, esta integral es imposible de resolver anal√≠ticamente. MCMC nos ayuda a aproximar la distribuci√≥n posterior sin necesidad de calcular $P(D)$.

## ¬øC√≥mo funciona MCMC?

MCMC **simula valores** de los par√°metros siguiendo estos pasos:

1.  **Empieza en un valor inicial** .

2.  **Propone un nuevo valor** basado en una distribuci√≥n de transici√≥n.

3.  **Decide si acepta o rechaza** seg√∫n la regla de aceptaci√≥n.

4.  **Repite el proceso muchas veces** para construir una cadena de valores que sigan la distribuci√≥n posterior.

üîπ **Importante:**\
Con suficientes iteraciones, la cadena **converge** a la distribuci√≥n posterior, permitiendo estimar par√°metros de manera precisa.

## M√©todos populares de MCMC

Existen varias formas de implementar MCMC. Las m√°s comunes son:

‚úÖ **1. Algoritmo de Metropolis-Hastings**

-   Propone un nuevo valor $\theta^*$.

-   Decide si lo acepta o no comparando la raz√≥n de aceptaci√≥n:

    $$
    r = \frac{P(D | \theta^*) P(\theta^*)}{P(D | \theta) P(\theta)}
    $$

    -   Si $r \geq 1$, acepta $\theta^*$.
    -   Si $r < 1$, acepta $\theta^*$ con probabilidad $r$.

Se usa cuando no se conoce la forma exacta de la distribuci√≥n posterior.

## ¬øC√≥mo saber si una cadena ha convergido?

![](/images/rebvayes/53482247_2120318871350183_7589131882600595456_n.jpg){fig-align="center" width="350"}

Algunas t√©cnicas comunes para evaluar la convergencia incluyen:

-   **Inspecci√≥n visual de trazas**: un gr√°fico de trazas muestra si la cadena ha alcanzado un comportamiento estable sin tendencias obvias.

-   **Tama√±o de muestra efectivo (Effective Sample Size, ESS)**: Dado que las muestras en MCMC est√°n correlacionadas, el n√∫mero real de muestras independientes es menor que el n√∫mero total de iteraciones. El tama√±o de muestra efectivo (ESS) estima cu√°ntas muestras independientes equivalentes hay en la cadena.

Se calcula como:

$$
ESS = \frac{N}{1 + 2 \sum \rho_k}
$$

Donde $N$ es el n√∫mero total de iteraciones y $\rho_k$ es la autocorrelaci√≥n en el retraso $k$. **Un ESS alto (**$ESS > 200$) indica que la cadena ha explorado bien el espacio de par√°metros y proporciona estimaciones confiables.

Un ESS bajo sugiere que las muestras est√°n altamente correlacionadas y que se necesitan m√°s iteraciones o una mejor parametrizaci√≥n del algoritmo para obtener estimaciones m√°s precisas.

Para visualizar estos valores y generar gr√°ficos, se puede utilizar **Tracer**, una herramienta que facilita el an√°lisis de convergencia de cadenas MCMC. Se puede descargar en el siguiente enlace:

[Tracer v1.7.2](https://github.com/beast-dev/tracer/releases/tag/v1.7.2)

# Modelos Gr√°ficos en RevBayes

En RevBayes, un **modelo gr√°fico** representa la relaci√≥n entre variables aleatorias en un modelo bayesiano. Cada variable en el modelo es representada por un **nodo**, y las relaciones entre ellas se representan como **bordes en un grafo**.

![](/images/rebvayes/graphical_model_legend.png){fig-align="center" width="450"}

## Tipos de Nodos en RevBayes

### üëâ **Nodos Constantes**

Son valores fijos dentro del modelo. No tienen incertidumbre.

```         
n = 10  # N√∫mero de observaciones
```

### üëâ **Nodos Estoc√°sticos**

Representan **variables aleatorias** con una distribuci√≥n. Son los par√°metros del modelo.

```         
theta ~ dnBeta(2,2)  # Prior Beta(2,2)
```

En este caso, `theta` es una variable aleatoria con una distribuci√≥n Beta.

### üëâ **Nodos Deterministas**

Son **valores calculados** a partir de otros nodos.

```         
mu := theta * n  # Media esperada
```

Aqu√≠, `mu` se calcula a partir de `theta` y `n`.

### üëâ **Nodos Clamped (Observados)**

Se utilizan para fijar valores observados en el modelo.

```         
D ~ dnBinomial(n, theta)  # Modelo Binomial
D.clamp(7)  # Observamos 7 √©xitos
```

En este caso, `D` es una variable aleatoria Binomial, pero la fijamos en `7`.

### üëâ **Nodos Plate**

Los **plates** se usan para **repetir estructuras** en modelos jer√°rquicos.

```         
for (i in 1:10) {
    theta[i] ~ dnBeta(2,2)
}
```

Aqu√≠, estamos creando **10 valores de `theta`**, cada uno con una distribuci√≥n Beta(2,2).

# Comparaci√≥n entre RevBayes y R

RevBayes tiene una sintaxis similar a **R**, pero existen diferencias clave:

|                              |                                              |                                 |
|------------------------------|----------------------------------------------|---------------------------------|
| **Caracter√≠stica**           | **RevBayes**                                 | **R**                           |
| **Declaraci√≥n de variables** | `theta ~ dnBeta(2,2)`                        | `theta <- rbeta(1, 2, 2)`       |
| **Estructuras de control**   | `for (i in 1:10) {}`                         | `for (i in 1:10) {}`            |
| **Funciones definidas**      | `function myFunc(x) { return(x^2) }`         | `myFunc <- function(x) { x^2 }` |
| **Asignaci√≥n de valores**    | `:=` para deterministas, `=` para constantes | `<-` para todo                  |
| **Inferencia Bayesiana**     | Integrada con `mcmc()`                       | Necesita paquetes adicionales   |

# üìä Ejemplo Micheladas en Tepito

Queremos estimar la probabilidad **( p )** de que un estudiante disfrute del ambiente en las **micheladas en Tepito**.

Hemos recopilado informaci√≥n de estudiantes que visitaron el lugar:

‚úîÔ∏è **10 estudiantes fueron encuestados**\
‚úîÔ∏è **7 estudiantes disfrutaron el ambiente**, **3 no lo disfrutaron**\
‚úîÔ∏è Queremos estimar la probabilidad de que **t√∫**, como nuevo visitante, disfrutes del ambiente.

------------------------------------------------------------------------

## üîπ 1. Definiendo el Modelo en RevBayes

### üìå **Distribuci√≥n Prior**

Antes de ver los datos, asumimos una **creencia previa** sobre la probabilidad **( p )**.\
Utilizamos una **distribuci√≥n Beta(8,2)**, basada en la suposici√≥n de que aproximadamente el **80%** de las personas disfrutar√°n del ambiente.

$$
p \sim \text{Beta}(8,2)
$$

[P√°gina para visualizar las distribuciones para RevBayes](https://mikeryanmay.shinyapps.io/plotprior/), pega el siguiente c√≥digo en Rev code:

``` r
x ~ dnBeta(8, 2)
```

La media de esta distribuci√≥n es:

$$
E[p] = \frac{\alpha}{\alpha + \beta} = \frac{8}{8+2} = 0.8
$$

------------------------------------------------------------------------

### üìå **Verosimilitud (Likelihood)**

La verosimilitud describe la probabilidad de observar los datos dados un valor espec√≠fico de **( p )**.\
Como cada estudiante puede estar **satisfecho (√©xito)** o **insatisfecho (fracaso)**, usamos una **distribuci√≥n Binomial**:

$$
k \sim \text{Binomial}(n = 10, p)
$$

Donde: - ( k = 7 ) es el n√∫mero de estudiantes satisfechos observados. - ( n = 10 ) es el n√∫mero total de encuestados.

------------------------------------------------------------------------

### üìå **Posterior Bayesiana**

Aplicamos el **Teorema de Bayes**:

$$
P(p | D) \propto P(D | p) P(p)
$$

Dado que usamos un **prior Beta** y una **verosimilitud Binomial**, la posterior tambi√©n sigue una **distribuci√≥n Beta** con par√°metros actualizados:

$$
p | D \sim \text{Beta}(8+7, 2+3) = \text{Beta}(15,5)
$$

La **media de la posterior** nos da la mejor estimaci√≥n despu√©s de observar los datos:

$$
E[p] = \frac{15}{15 + 5} = 0.75
$$

Esto significa que, **despu√©s de observar que 7 de 10 estudiantes disfrutaron el ambiente**, nuestra mejor estimaci√≥n de la probabilidad de que t√∫ disfrutes del ambiente es **75%**.

------------------------------------------------------------------------

## üîπ 2. C√≥digo en RevBayes

A continuaci√≥n, presentamos el c√≥digo en **RevBayes** para implementar este modelo y ejecutar un an√°lisis MCMC.

![](/images/rebvayes/binomial_graphical_model.png){fig-alt="Modelo Grafico" fig-align="center" width="250"}

``` r
# ------------------------------------------------
# RevBayes - Algoritmo de Metropolis-Hastings para estimar
# la probabilidad de disfrutar el ambiente en las micheladas de Tepito
# ------------------------------------------------

# Datos observados
total_clientes <- 10  # N√∫mero total de encuestados
satisfechos <- 7      # N√∫mero de estudiantes que disfrutaron el ambiente

# Especificar la distribuci√≥n prior
alpha <- 8   # Basado en la creencia previa de 80% satisfacci√≥n
beta  <- 2   # Complemento del prior
p ~ dnBeta(alpha, beta)  # Prior Beta(8,2)

# Definir la propuesta de MCMC con Metropolis-Hastings
moves[1] = mvSlide(p, delta=0.1, weight=1)  # Movimiento en la distribuci√≥n de p

# Especificar el modelo de verosimilitud (distribuci√≥n Binomial)
k ~ dnBinomial(p, total_clientes)
k.clamp(satisfechos)  # Fijar la observaci√≥n de 7 estudiantes satisfechos

# Crear el modelo
my_model = model(p)

# Definir monitores para el MCMC
monitors[1] = mnModel(filename="micheladas_MH.log", printgen=10, separator = TAB)  # Guardar resultados
monitors[2] = mnScreen(printgen=100, p)  # Mostrar progreso cada 100 generaciones

# Crear el an√°lisis MCMC con Metropolis-Hastings
analysis = mcmc(my_model, monitors, moves)

# Ejecutar el MCMC con 100,000 iteraciones
analysis.run(100000)

# Mostrar el resumen de los operadores de MCMC
analysis.operatorSummary()
```

## Mini-ejercicio

1.  **Crea un script** para RevBayes (`.Rev`) utilizando `Visual Studio Code` y copia el codigo.

2.  **Modifica el prior** `dnBeta(alpha, beta)` con los valores que reflejen tu creencia sobre la probabilidad de satisfacci√≥n.

3.  **Guarda el archivo `micheladas_MH.log`** en la carpeta asiganada para guardar resultados.

4.  **Guarda el script** en la carpeta de `scripts`.

5.  **Ejecuta el an√°lisis** MCMC en RevBayes.

6.  **Visualiza los resultados** usando `Tracer` para observar la distribuci√≥n posterior.
